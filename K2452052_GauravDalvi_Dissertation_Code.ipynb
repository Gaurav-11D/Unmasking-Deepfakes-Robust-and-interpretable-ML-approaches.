{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42c917b",
   "metadata": {},
   "source": [
    "\n",
    "# Unmasking Deepfakes: Robust and Interpretable ML Approaches\n",
    "**Author:** Gaurav Dalvi \n",
    "**Use:** Paste your dataset path and run top-to-bottom.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b9d94",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a557e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing into: /Users/zaddyd/Desktop/DeepFake Detection Project/.venv/bin/python\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scikit-image in ./.venv/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.22 in ./.venv/lib/python3.11/site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8 in ./.venv/lib/python3.11/site-packages (from scikit-image) (1.16.2)\n",
      "Requirement already satisfied: networkx>=2.8 in ./.venv/lib/python3.11/site-packages (from scikit-image) (3.5)\n",
      "Requirement already satisfied: pillow>=9.0.1 in ./.venv/lib/python3.11/site-packages (from scikit-image) (11.3.0)\n",
      "Requirement already satisfied: imageio>=2.27 in ./.venv/lib/python3.11/site-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.11/site-packages (from scikit-image) (2025.9.9)\n",
      "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.11/site-packages (from scikit-image) (25.0)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in ./.venv/lib/python3.11/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: tensorflow==2.16.* in ./.venv/lib/python3.11/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.75.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.11.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.16.*) (0.45.1)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (14.1.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.*) (0.1.2)\n",
      "Done. Restart the kernel if imports still fail (but try the next cell first).\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, pkgutil\n",
    "\n",
    "print(\"Installing into:\", sys.executable)\n",
    "\n",
    "# Packages we need (TF 2.16 works with Python 3.11)\n",
    "pkgs = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"scikit-learn\",\n",
    "    \"scikit-image\",\n",
    "    \"opencv-python\",\n",
    "    \"matplotlib\",\n",
    "    \"joblib\",\n",
    "    \"tensorflow==2.16.*\",  # regular TF; 'tensorflow-metal' is optional\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
    "    except subprocess.CalledProcessError:\n",
    "        # fallback for locked systems\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", p])\n",
    "\n",
    "print(\"Done. Restart the kernel if imports still fail (but try the next cell first).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad90d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing into: /Users/zaddyd/Desktop/DeepFake Detection Project/.venv/bin/python\n",
      "Requirement already satisfied: numpy==1.26.4 in ./.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow==2.16.* in ./.venv/lib/python3.11/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.75.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (3.11.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.*) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.16.*) (0.45.1)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (14.1.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.*) (0.1.2)\n",
      "Requirement already satisfied: opencv-python==4.10.0.84 in ./.venv/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.11/site-packages (from opencv-python==4.10.0.84) (1.26.4)\n",
      "Requirement already satisfied: scikit-image==0.22.0 in ./.venv/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.22 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (1.16.2)\n",
      "Requirement already satisfied: networkx>=2.8 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (3.5)\n",
      "Requirement already satisfied: pillow>=9.0.1 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (11.3.0)\n",
      "Requirement already satisfied: imageio>=2.27 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (2025.9.9)\n",
      "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (25.0)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in ./.venv/lib/python3.11/site-packages (from scikit-image==0.22.0) (0.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (1.5.2)\n",
      "Done. If imports still use old versions, restart the kernel and run the next cell.\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "print(\"Installing into:\", sys.executable)\n",
    "# Keep versions compatible with TF 2.16\n",
    "pkgs = [\n",
    "    \"numpy==1.26.4\",\n",
    "    \"tensorflow==2.16.*\",\n",
    "    \"opencv-python==4.10.0.84\",\n",
    "    \"scikit-image==0.22.0\",   # works well with numpy 1.26\n",
    "    \"pandas\",\n",
    "    \"scikit-learn\",\n",
    "    \"matplotlib\",\n",
    "    \"joblib\",\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", p])\n",
    "\n",
    "print(\"Done. If imports still use old versions, restart the kernel and run the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4126fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.13 (main, Jun  3 2025, 18:38:25) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "NumPy: 1.26.4\n",
      "Pandas: 2.3.2\n",
      "scikit-image: 0.22.0\n",
      "scikit-learn: 1.7.2\n",
      "OpenCV: 4.10.0\n",
      "TensorFlow: 2.16.2\n",
      "Artefacts dir: /Users/zaddyd/Desktop/DeepFake Detection Project/artefacts\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, json, time, random, shutil, gc, itertools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "                             confusion_matrix, roc_curve, auc, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "\n",
    "# Prefer new location + American spelling\n",
    "try:\n",
    "    from skimage.feature.texture import graycomatrix, graycoprops  # skimage >= 0.20\n",
    "except Exception:\n",
    "    try:\n",
    "        from skimage.feature import graycomatrix, graycoprops      # sometimes re-exported\n",
    "    except Exception:\n",
    "        # Last resort: older API (British spelling)\n",
    "        from skimage.feature import greycomatrix as graycomatrix, greycoprops as graycoprops\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg16, resnet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "import skimage, sklearn\n",
    "print(\"scikit-image:\", skimage.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "# Create artefacts dir\n",
    "ARTE_DIR = Path(\"artefacts\")\n",
    "ARTE_DIR.mkdir(exist_ok=True)\n",
    "print(\"Artefacts dir:\", ARTE_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ae9ac",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a65ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root: /Users/zaddyd/Desktop/DeepFake Detection Project/PhDPeterDetaset\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = Path(\"/Users/zaddyd/Desktop/DeepFake Detection Project/PhDPeterDetaset\")\n",
    "\n",
    "# If your class folder names differ (e.g., 'fake' vs 'real'), update here:\n",
    "CLASS_NAMES = [\"fake\", \"real\"]  # order matters for label encoding\n",
    "\n",
    "# Image sizing for feature extraction\n",
    "IMG_SIZE = (224, 224)  # for CNN backbones\n",
    "GRAY_SIZE = (256, 256) # for handcrafted features; kept slightly larger for textures\n",
    "\n",
    "# Feature flags\n",
    "USE_LBP = True\n",
    "USE_HOG = True\n",
    "USE_GLCM = True\n",
    "USE_DCT = True\n",
    "\n",
    "USE_VGG16 = True\n",
    "USE_RESNET50 = False  # You can enable later if you want to concatenate both CNNs\n",
    "\n",
    "# Compute controls\n",
    "MAX_IMAGES_PER_CLASS_PER_SPLIT = None   # e.g., 150 to cap; set None for all\n",
    "CACHE_DIR = Path(\"cache_features\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# SVM / RF configs\n",
    "SVM_C = 10.0\n",
    "SVM_KERNEL = \"rbf\"\n",
    "SVM_GAMMA = \"scale\"\n",
    "\n",
    "RF_TREES = 300\n",
    "RF_MAX_DEPTH = None\n",
    "\n",
    "# Robustness perturbations\n",
    "ROBUSTNESS = {\n",
    "    \"jpeg_50\": {\"jpeg_quality\": 50},\n",
    "    \"blur_3\": {\"blur_ksize\": 3},\n",
    "    \"gauss_noise_0.02\": {\"gauss_sigma\": 0.02},\n",
    "}\n",
    "\n",
    "print(\"Dataset root:\", DATASET_ROOT.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139817b",
   "metadata": {},
   "source": [
    "## 3. Dataset Scan & Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd82ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (14000, 3)\n",
      "val : (6000, 3)\n",
      "test : (2000, 3)\n",
      "Saved split indices to artefacts/.\n"
     ]
    }
   ],
   "source": [
    "def scan_split(split_dir: Path, class_names, max_per_class=None):\n",
    "    rows = []\n",
    "    for lbl, cname in enumerate(class_names):\n",
    "        cdir = split_dir / cname\n",
    "        if not cdir.exists():\n",
    "            continue\n",
    "        images = []\n",
    "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.tif\",\"*.tiff\",\"*.webp\"):\n",
    "            images.extend(list(cdir.rglob(ext)))\n",
    "        if max_per_class:\n",
    "            images = images[:max_per_class]\n",
    "        for p in images:\n",
    "            rows.append({\"path\": str(p), \"label\": lbl, \"class\": cname})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def build_index(root: Path, class_names, max_per_class=None):\n",
    "    idx = {}\n",
    "    for split in [\"train\",\"val\",\"test\"]:\n",
    "        split_dir = root / split\n",
    "        if not split_dir.exists():\n",
    "            print(f\"[WARN] Missing split: {split_dir}\")\n",
    "            idx[split] = pd.DataFrame(columns=[\"path\",\"label\",\"class\"])\n",
    "        else:\n",
    "            idx[split] = scan_split(split_dir, class_names, max_per_class)\n",
    "            print(split, \":\", idx[split].shape)\n",
    "    return idx\n",
    "\n",
    "index = build_index(DATASET_ROOT, CLASS_NAMES, MAX_IMAGES_PER_CLASS_PER_SPLIT)\n",
    "\n",
    "# Save indices\n",
    "for k,v in index.items():\n",
    "    v.to_csv(ARTE_DIR / f\"{k}_index.csv\", index=False)\n",
    "print(\"Saved split indices to artefacts/.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57ef2d",
   "metadata": {},
   "source": [
    "## 4. Handcrafted Feature Extractors (LBP, HOG, GLCM, DCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d12d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample handcrafted feat length: 2870\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, transform, util\n",
    "from skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\n",
    "\n",
    "# Define constants if not set earlier\n",
    "GRAY_SIZE = (128, 128)  # adjust to your project\n",
    "USE_LBP = True\n",
    "USE_HOG = True\n",
    "USE_GLCM = True\n",
    "USE_DCT = True\n",
    "\n",
    "\n",
    "def read_gray(path, size=GRAY_SIZE):\n",
    "    img = io.imread(path)\n",
    "    if img.ndim == 3:\n",
    "        img = color.rgb2gray(img)\n",
    "    img = transform.resize(img, size, anti_aliasing=True)\n",
    "    img = util.img_as_float32(img)\n",
    "    return img\n",
    "\n",
    "def feat_lbp(gray, P=8, R=1):\n",
    "    # LBP expects integers; convert to uint8 to suppress warnings\n",
    "    g8 = util.img_as_ubyte(gray)  # uint8 [0..255]\n",
    "    lbp = local_binary_pattern(g8, P=P, R=R, method=\"uniform\")\n",
    "    n_bins = P + 2\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_bins+1), density=True)\n",
    "    return hist.astype(np.float32)\n",
    "\n",
    "def feat_hog(gray):\n",
    "    h = hog(gray, orientations=9, pixels_per_cell=(16,16), cells_per_block=(2,2),\n",
    "            block_norm=\"L2-Hys\", transform_sqrt=True, feature_vector=True)\n",
    "    return h.astype(np.float32)\n",
    "\n",
    "def feat_glcm(gray):\n",
    "    g8 = util.img_as_ubyte(gray)  # uint8\n",
    "    distances = [1, 2, 4]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    glcm = graycomatrix(g8, distances=distances, angles=angles,\n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    props = []\n",
    "    for prop in [\"contrast\",\"dissimilarity\",\"homogeneity\",\"ASM\",\"energy\",\"correlation\"]:\n",
    "        props.append(graycoprops(glcm, prop).ravel())\n",
    "    return np.concatenate(props).astype(np.float32)\n",
    "\n",
    "def feat_dct(gray, keep=32):\n",
    "    # resize to square small size for stable DCT\n",
    "    g = transform.resize(gray, (128,128), anti_aliasing=True)\n",
    "    g32 = np.float32(g)\n",
    "    dct = cv2.dct(g32)\n",
    "    # take top-left kxk low frequencies\n",
    "    k = keep\n",
    "    block = dct[:k, :k]\n",
    "    return block.flatten().astype(np.float32)\n",
    "\n",
    "def handcrafted_features(path):\n",
    "    gray = read_gray(path)\n",
    "    feats = []\n",
    "    if USE_LBP:\n",
    "        feats.append(feat_lbp(gray))\n",
    "    if USE_HOG:\n",
    "        feats.append(feat_hog(gray))\n",
    "    if USE_GLCM:\n",
    "        feats.append(feat_glcm(gray))\n",
    "    if USE_DCT:\n",
    "        feats.append(feat_dct(gray, keep=32))\n",
    "    if len(feats)==0:\n",
    "        return np.empty((0,), dtype=np.float32)\n",
    "    return np.concatenate(feats)\n",
    "\n",
    "# Quick smoke test on first available image (optional)\n",
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    if len(index[split])>0:\n",
    "        sample_path = index[split][\"path\"].iloc[0]\n",
    "        print(\"Sample handcrafted feat length:\", handcrafted_features(sample_path).shape[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de3153",
   "metadata": {},
   "source": [
    "## 5. CNN Embeddings (VGG16 / ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515dc861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 embedding output: (None, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg_model = None\n",
    "resnet_model = None\n",
    "\n",
    "if USE_VGG16:\n",
    "    base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    vgg_model = Model(inputs=base.input, outputs=tf.keras.layers.GlobalAveragePooling2D()(base.output))\n",
    "    print(\"VGG16 embedding output:\", vgg_model.output_shape)\n",
    "\n",
    "if USE_RESNET50:\n",
    "    base_r = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    resnet_model = Model(inputs=base_r.input, outputs=tf.keras.layers.GlobalAveragePooling2D()(base_r.output))\n",
    "    print(\"ResNet50 embedding output:\", resnet_model.output_shape)\n",
    "\n",
    "def read_rgb_for_cnn(path, size=IMG_SIZE):\n",
    "    img = kimage.load_img(path, target_size=size)\n",
    "    arr = kimage.img_to_array(img)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "def cnn_embed_batch(paths, backbone=\"vgg\"):\n",
    "    # batch predict for speed\n",
    "    X = []\n",
    "    preprocess = vgg_preprocess if backbone==\"vgg\" else resnet_preprocess\n",
    "    model = vgg_model if backbone==\"vgg\" else resnet_model\n",
    "    # guard\n",
    "    if model is None:\n",
    "        return np.zeros((len(paths), 0), dtype=np.float32)\n",
    "    batch = []\n",
    "    for p in paths:\n",
    "        arr = read_rgb_for_cnn(p)\n",
    "        batch.append(arr[0])\n",
    "    batch = np.stack(batch, axis=0)\n",
    "    batch = preprocess(batch.copy())\n",
    "    emb = model.predict(batch, verbose=0)\n",
    "    return emb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a822f8",
   "metadata": {},
   "source": [
    "## 6. Extract & Cache Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb9ab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train handcrafted: (14000, 2870) vgg: (14000, 512) resnet: (14000, 0) labels: (14000,)\n",
      "val handcrafted: (6000, 2870) vgg: (6000, 512) resnet: (6000, 0) labels: (6000,)\n",
      "test handcrafted: (2000, 2870) vgg: (2000, 512) resnet: (2000, 0) labels: (2000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_split_features(df, split, cache_dir=CACHE_DIR):\n",
    "    cache_path = cache_dir / f\"{split}_features.npz\"\n",
    "    if cache_path.exists():\n",
    "        data = np.load(cache_path, allow_pickle=True)\n",
    "        return (data[\"X_hand\"], data[\"X_vgg\"], data[\"X_resnet\"], data[\"y\"])\n",
    "\n",
    "    paths = df[\"path\"].tolist()\n",
    "    y = df[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "    # Handcrafted\n",
    "    Xh = []\n",
    "    for i,p in enumerate(paths):\n",
    "        Xh.append(handcrafted_features(p))\n",
    "        if (i+1)%100==0:\n",
    "            print(f\"{split}: handcrafted {i+1}/{len(paths)}\")\n",
    "    Xh = np.stack(Xh, axis=0) if len(Xh)>0 else np.zeros((len(paths),0), dtype=np.float32)\n",
    "\n",
    "    # CNNs\n",
    "    Xv = cnn_embed_batch(paths, backbone=\"vgg\") if USE_VGG16 else np.zeros((len(paths),0), dtype=np.float32)\n",
    "    Xr = cnn_embed_batch(paths, backbone=\"resnet\") if USE_RESNET50 else np.zeros((len(paths),0), dtype=np.float32)\n",
    "\n",
    "    np.savez_compressed(cache_path, X_hand=Xh, X_vgg=Xv, X_resnet=Xr, y=y)\n",
    "    return (Xh, Xv, Xr, y)\n",
    "\n",
    "feat = {}\n",
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    if len(index[split])==0:\n",
    "        feat[split] = (np.zeros((0,0)), np.zeros((0,0)), np.zeros((0,0)), np.zeros((0,)))\n",
    "        continue\n",
    "    feat[split] = extract_split_features(index[split], split)\n",
    "    print(split, \"handcrafted:\", feat[split][0].shape, \"vgg:\", feat[split][1].shape, \"resnet:\", feat[split][2].shape, \"labels:\", feat[split][3].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de597f6a",
   "metadata": {},
   "source": [
    "## 7. Feature Fusion & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fabe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fused shape: (14000, 3382)\n",
      "Val fused shape: (6000, 3382)\n",
      "Test fused shape: (2000, 3382)\n"
     ]
    }
   ],
   "source": [
    "def fuse_features(Xh, Xv, Xr):\n",
    "    parts = [X for X in [Xh, Xv, Xr] if X is not None and X.size>0]\n",
    "    if len(parts)==0:\n",
    "        raise ValueError(\"No features enabled. Enable at least one handcrafted or CNN feature.\")\n",
    "    return np.concatenate(parts, axis=1)\n",
    "\n",
    "def split_trainval(feat_dict):\n",
    "    Xh_tr, Xv_tr, Xr_tr, y_tr = feat_dict[\"train\"]\n",
    "    Xh_va, Xv_va, Xr_va, y_va = feat_dict[\"val\"]\n",
    "    Xh_te, Xv_te, Xr_te, y_te = feat_dict[\"test\"]\n",
    "\n",
    "    X_tr = fuse_features(Xh_tr, Xv_tr, Xr_tr)\n",
    "    X_va = fuse_features(Xh_va, Xv_va, Xr_va) if Xh_va.size+Xv_va.size+Xr_va.size>0 else None\n",
    "    X_te = fuse_features(Xh_te, Xv_te, Xr_te) if Xh_te.size+Xv_te.size+Xr_te.size>0 else None\n",
    "    return X_tr, y_tr, X_va, y_va, X_te, y_te\n",
    "\n",
    "X_tr, y_tr, X_va, y_va, X_te, y_te = split_trainval(feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_trs = scaler.fit_transform(X_tr)\n",
    "X_vas = scaler.transform(X_va) if X_va is not None and X_va.size>0 else None\n",
    "X_tes = scaler.transform(X_te) if X_te is not None and X_te.size>0 else None\n",
    "\n",
    "print(\"Train fused shape:\", X_trs.shape)\n",
    "if X_vas is not None: print(\"Val fused shape:\", X_vas.shape)\n",
    "if X_tes is not None: print(\"Test fused shape:\", X_tes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2aade",
   "metadata": {},
   "source": [
    "## 8. Train Classifiers (SVM, RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce41059",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# SVM\n",
    "svm_clf = SVC(C=SVM_C, kernel=SVM_KERNEL, gamma=SVM_GAMMA, probability=True, random_state=42)\n",
    "svm_clf.fit(X_trs, y_tr)\n",
    "models[\"SVM\"] = svm_clf\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=RF_TREES, max_depth=RF_MAX_DEPTH, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_trs, y_tr)\n",
    "models[\"RF\"] = rf_clf\n",
    "\n",
    "print(\"Trained models:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3e087",
   "metadata": {},
   "source": [
    "## 9. Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c374002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(name, clf, X, y, split_name):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_proba = None\n",
    "    try:\n",
    "        y_proba = clf.predict_proba(X)[:,1]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, y_pred, average=\"binary\", pos_label=1, zero_division=0)\n",
    "    metrics = {\"model\":name, \"split\":split_name, \"accuracy\":acc, \"precision\":prec, \"recall\":rec, \"f1\":f1}\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            auc_roc = roc_auc_score(y, y_proba)\n",
    "        except Exception:\n",
    "            auc_roc = np.nan\n",
    "        metrics[\"auc\"] = auc_roc\n",
    "    else:\n",
    "        metrics[\"auc\"] = np.nan\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred, labels=[0,1])\n",
    "    return metrics, cm, (y, y_pred, y_proba)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, fname):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    # annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(ARTE_DIR / fname, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(y_true, y_proba, title, fname):\n",
    "    if y_proba is None:\n",
    "        print(\"[ROC] Skipping (no probabilities available)\")\n",
    "        return\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(ARTE_DIR / fname, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5d5ee",
   "metadata": {},
   "source": [
    "## 10. In-dataset Evaluation (Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "for name, clf in models.items():\n",
    "    if X_vas is not None:\n",
    "        m, cm, triplet = eval_model(name, clf, X_vas, y_va, \"val\")\n",
    "        results.append(m)\n",
    "        plot_confusion_matrix(cm, classes=CLASS_NAMES, title=f\"{name} Confusion Matrix (val)\", fname=f\"{name}_cm_val.png\")\n",
    "        plot_roc(triplet[0], triplet[2], title=f\"{name} ROC (val)\", fname=f\"{name}_roc_val.png\")\n",
    "\n",
    "    if X_tes is not None:\n",
    "        m, cm, triplet = eval_model(name, clf, X_tes, y_te, \"test\")\n",
    "        results.append(m)\n",
    "        plot_confusion_matrix(cm, classes=CLASS_NAMES, title=f\"{name} Confusion Matrix (test)\", fname=f\"{name}_cm_test.png\")\n",
    "        plot_roc(triplet[0], triplet[2], title=f\"{name} ROC (test)\", fname=f\"{name}_roc_test.png\")\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(ARTE_DIR / \"results_indataset.csv\", index=False)\n",
    "print(res_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51453a",
   "metadata": {},
   "source": [
    "## 11. Robustness Evaluation (JPEG, Blur, Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_perturbations_to_paths(paths, tag):\n",
    "    # returns list of temp file paths after applying a perturbation\n",
    "    tmp_dir = Path(\"tmp_perturb\") / tag\n",
    "    if tmp_dir.exists():\n",
    "        shutil.rmtree(tmp_dir)\n",
    "    tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out_paths = []\n",
    "    for p in paths:\n",
    "        img = io.imread(p)\n",
    "        if img.ndim == 2:\n",
    "            img = color.gray2rgb(img)\n",
    "        img = util.img_as_ubyte(img)\n",
    "\n",
    "        if \"jpeg_quality\" in ROBUSTNESS[tag]:\n",
    "            q = ROBUSTNESS[tag][\"jpeg_quality\"]\n",
    "            tmp = tmp_dir / (Path(p).stem + f\"_jpeg{q}.jpg\")\n",
    "            cv2.imwrite(str(tmp), cv2.cvtColor(img, cv2.COLOR_RGB2BGR), [int(cv2.IMWRITE_JPEG_QUALITY), q])\n",
    "            out_paths.append(str(tmp))\n",
    "        elif \"blur_ksize\" in ROBUSTNESS[tag]:\n",
    "            k = ROBUSTNESS[tag][\"blur_ksize\"]\n",
    "            if k%2==0: k += 1\n",
    "            bl = cv2.GaussianBlur(cv2.cvtColor(img, cv2.COLOR_RGB2BGR), (k,k), 0)\n",
    "            tmp = tmp_dir / (Path(p).stem + f\"_blur{k}.png\")\n",
    "            cv2.imwrite(str(tmp), bl)\n",
    "            out_paths.append(str(tmp))\n",
    "        elif \"gauss_sigma\" in ROBUSTNESS[tag]:\n",
    "            s = ROBUSTNESS[tag][\"gauss_sigma\"]\n",
    "            noise = np.random.normal(0, s*255, img.shape).astype(np.int16)\n",
    "            noisy = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "            tmp = tmp_dir / (Path(p).stem + f\"_noise{s}.png\")\n",
    "            cv2.imwrite(str(tmp), cv2.cvtColor(noisy, cv2.COLOR_RGB2BGR))\n",
    "            out_paths.append(str(tmp))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown perturbation spec.\")\n",
    "    return out_paths\n",
    "\n",
    "def features_from_paths(paths):\n",
    "    # handcrafted\n",
    "    Xh = []\n",
    "    for i,p in enumerate(paths):\n",
    "        Xh.append(handcrafted_features(p))\n",
    "        if (i+1)%100==0:\n",
    "            print(f\"perturb: handcrafted {i+1}/{len(paths)}\")\n",
    "    Xh = np.stack(Xh, axis=0) if len(Xh)>0 else np.zeros((len(paths),0), dtype=np.float32)\n",
    "    # cnn\n",
    "    Xv = cnn_embed_batch(paths, backbone=\"vgg\") if USE_VGG16 else np.zeros((len(paths),0), dtype=np.float32)\n",
    "    Xr = cnn_embed_batch(paths, backbone=\"resnet\") if USE_RESNET50 else np.zeros((len(paths),0), dtype=np.float32)\n",
    "    X = fuse_features(Xh, Xv, Xr)\n",
    "    Xs = scaler.transform(X)\n",
    "    return Xs\n",
    "\n",
    "if X_tes is not None and len(index[\"test\"])>0:\n",
    "    test_paths = index[\"test\"][\"path\"].tolist()\n",
    "    rob_results = []\n",
    "    for tag in ROBUSTNESS.keys():\n",
    "        ppaths = apply_perturbations_to_paths(test_paths, tag)\n",
    "        Xp = features_from_paths(ppaths)\n",
    "        y = index[\"test\"][\"label\"].astype(int).to_numpy()\n",
    "        for name, clf in models.items():\n",
    "            m, cm, triplet = eval_model(name, clf, Xp, y, f\"test_{tag}\")\n",
    "            rob_results.append(m)\n",
    "            plot_confusion_matrix(cm, classes=CLASS_NAMES, title=f\"{name} Confusion Matrix (test {tag})\", fname=f\"{name}_cm_test_{tag}.png\")\n",
    "            plot_roc(triplet[0], triplet[2], title=f\"{name} ROC (test {tag})\", fname=f\"{name}_roc_test_{tag}.png\")\n",
    "    rob_df = pd.DataFrame(rob_results)\n",
    "    rob_df.to_csv(ARTE_DIR / \"results_robustness.csv\", index=False)\n",
    "    print(rob_df)\n",
    "else:\n",
    "    print(\"[Robustness] Skipped (no test set).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc129833",
   "metadata": {},
   "source": [
    "## 12. Best Model Selection + Report Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tabulate\"])\n",
    "\n",
    "def pick_best_by(res_df, metric=\"f1\", split=\"val\", fallback_split=\"test\"):\n",
    "    sub = res_df[res_df[\"split\"]==split]\n",
    "    if len(sub)==0 and fallback_split is not None:\n",
    "        sub = res_df[res_df[\"split\"]==fallback_split]\n",
    "    if len(sub)==0:\n",
    "        return None\n",
    "    row = sub.sort_values(by=metric, ascending=False).iloc[0].to_dict()\n",
    "    return row\n",
    "\n",
    "# Combine indataset + robustness if available\n",
    "tables = {}\n",
    "tables[\"in_dataset\"] = pd.read_csv(ARTE_DIR / \"results_indataset.csv\") if (ARTE_DIR / \"results_indataset.csv\").exists() else pd.DataFrame()\n",
    "tables[\"robustness\"] = pd.read_csv(ARTE_DIR / \"results_robustness.csv\") if (ARTE_DIR / \"results_robustness.csv\").exists() else pd.DataFrame()\n",
    "\n",
    "best = pick_best_by(tables[\"in_dataset\"], metric=\"f1\", split=\"val\", fallback_split=\"test\")\n",
    "print(\"Best (by F1):\", best)\n",
    "\n",
    "# Export nicely formatted tables (for dissertation Appendix A / Chapter 5)\n",
    "def format_table(df):\n",
    "    if \"auc\" in df.columns:\n",
    "        df[\"auc\"] = df[\"auc\"].round(4)\n",
    "    for col in [\"accuracy\",\"precision\",\"recall\",\"f1\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].round(4)\n",
    "    return df\n",
    "\n",
    "for name,df in tables.items():\n",
    "    if len(df)==0: continue\n",
    "    df2 = format_table(df.copy())\n",
    "    df2.to_csv(ARTE_DIR / f\"table_{name}.csv\", index=False)\n",
    "    with open(ARTE_DIR / f\"table_{name}.md\",\"w\") as f:\n",
    "        f.write(df2.to_markdown(index=False))\n",
    "    print(f\"[Saved] artefacts/table_{name}.csv and .md\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55193e00",
   "metadata": {},
   "source": [
    "## 13. Save Artefacts (Models, Scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b587ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, ARTE_DIR / \"scaler.joblib\")\n",
    "for name, clf in models.items():\n",
    "    joblib.dump(clf, ARTE_DIR / f\"model_{name}.joblib\")\n",
    "print(\"Saved scaler + models to artefacts/.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a2c24",
   "metadata": {},
   "source": [
    "## 14. Appendix: Environment & Config Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_info = {\n",
    "    \"python\": sys.version,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"scikit-image\": skimage.__version__,\n",
    "    \"scikit-learn\": sklearn.__version__,\n",
    "    \"opencv\": cv2.__version__,\n",
    "    \"tensorflow\": tf.__version__,\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"gray_size\": GRAY_SIZE,\n",
    "    \"use_features\": {\n",
    "        \"LBP\": USE_LBP, \"HOG\": USE_HOG, \"GLCM\": USE_GLCM, \"DCT\": USE_DCT,\n",
    "        \"VGG16\": USE_VGG16, \"RESNET50\": USE_RESNET50\n",
    "    },\n",
    "    \"svm\": {\"C\": SVM_C, \"kernel\": SVM_KERNEL, \"gamma\": SVM_GAMMA},\n",
    "    \"rf\": {\"trees\": RF_TREES, \"max_depth\": RF_MAX_DEPTH},\n",
    "    \"robustness\": ROBUSTNESS\n",
    "}\n",
    "with open(ARTE_DIR / \"environment_config.json\",\"w\") as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "print(json.dumps(env_info, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
